{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from typing import List, Dict, Callable\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Flatten\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                             question_text  target  \n",
       "0        How did Quebec nationalists see their province...       0  \n",
       "1        Do you have an adopted dog, how would you enco...       0  \n",
       "2        Why does velocity affect time? Does velocity a...       0  \n",
       "3        How did Otto von Guericke used the Magdeburg h...       0  \n",
       "4        Can I convert montra helicon D to a mountain b...       0  \n",
       "...                                                    ...     ...  \n",
       "1306117  What other technical skills do you need as a c...       0  \n",
       "1306118  Does MS in ECE have good job prospects in USA ...       0  \n",
       "1306119                          Is foam insulation toxic?       0  \n",
       "1306120  How can one start a research project based on ...       0  \n",
       "1306121  Who wins in a battle between a Wolverine and a...       0  \n",
       "\n",
       "[1306122 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('quora.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> List[str]:\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return [token for token in tokens if token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:10<00:00, 124857.25it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed = [preprocess(text) for text in tqdm(data.question_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = max(len(tokens) for tokens in preprocessed)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for tokens in preprocessed:\n",
    "    vocab.update(tokens)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_vocab = {word for word, count in vocab.items() if count >= 50}\n",
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "filtered = []\n",
    "\n",
    "for tokens in preprocessed:\n",
    "    ids = [word2id.get(token, 1) for token in tokens]\n",
    "    filtered.append([token if token in filtered_vocab else '<UNK>' for token in tokens])\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:10<00:00, 130011.26it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1306122, 132, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = lambda x: x\n",
    "tfidf = TfidfVectorizer(preprocessor=dummy, tokenizer=dummy, lowercase=False, vocabulary=word2id)\n",
    "tfidf.fit(filtered)\n",
    "\n",
    "tfidf_dict = {token: tfidf.idf_[idx] for token, idx in word2id.items()}\n",
    "X_tfidf = [np.array([tfidf_dict[token] for token in tokens]) for tokens in tqdm(filtered)]\n",
    "X_tfidf = np.expand_dims(pad_sequences(X_tfidf, maxlen=MAX_LEN), axis=-1)\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 132)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(X, maxlen=MAX_LEN)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.target.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, \\\n",
    "X_tfidf_train, X_tfidf_valid, \\\n",
    "y_train, y_valid = train_test_split(X, X_tfidf, y, test_size=0.05, stratify=y, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embedding experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(embeddings, weights = None):\n",
    "    return Flatten()(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(embeddings, weights = None):\n",
    "    return tf.math.reduce_mean(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(embeddings, weights = None):\n",
    "    return tf.math.reduce_sum(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(embeddings, weights):\n",
    "    return tf.squeeze(tf.matmul(embeddings, weights, transpose_a=True), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_dim: int = 100, pooling_fn: Callable = weighted_average,\n",
    "                hidden: int = 64, dropout_rate: float = 0.1, l2_rate: float = 1e-4,\n",
    "                output_dim: int = 1, lr: float = 1e-3):\n",
    "    inputs = Input(shape=(MAX_LEN,))\n",
    "    weights = Input(shape=(MAX_LEN, 1))\n",
    "    \n",
    "    embeddings = Embedding(input_dim=len(word2id), output_dim=embedding_dim)(inputs)\n",
    "    embeddings = Dropout(dropout_rate)(embeddings)\n",
    "    pool = pooling_fn(embeddings, weights)\n",
    "    \n",
    "    dense = Dense(hidden, activation='relu', kernel_regularizer=regularizers.l2(l2_rate))(pool)\n",
    "    dense = Dropout(dropout_rate)(dense)\n",
    "    \n",
    "    activation = 'sigmoid' if output_dim == 1 else 'softmax'\n",
    "    outputs = Dense(output_dim, activation=activation, kernel_regularizer=regularizers.l2(l2_rate))(dense)\n",
    "\n",
    "    model = Model(inputs=[inputs, weights], outputs=outputs)\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    loss = 'binary_crossentropy' if output_dim == 1 else 'categorical_crossentropy'\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(patience=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "303/303 [==============================] - 110s 364ms/step - loss: 0.1497 - accuracy: 0.9473 - val_loss: 0.1215 - val_accuracy: 0.9544\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 110s 363ms/step - loss: 0.1160 - accuracy: 0.9555 - val_loss: 0.1199 - val_accuracy: 0.9545\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 110s 362ms/step - loss: 0.1090 - accuracy: 0.9579 - val_loss: 0.1220 - val_accuracy: 0.9540\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 110s 362ms/step - loss: 0.1012 - accuracy: 0.9613 - val_loss: 0.1272 - val_accuracy: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33474b37b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(embedding_dim=100, pooling_fn=concatenate, hidden=128, lr=0.0025)\n",
    "\n",
    "model.fit([X_train, X_tfidf_train], y_train, \n",
    "          validation_data=([X_valid, X_tfidf_valid], y_valid),\n",
    "          batch_size=4096,\n",
    "          callbacks=callbacks,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     61266\n",
      "           1       0.65      0.52      0.58      4041\n",
      "\n",
      "    accuracy                           0.95     65307\n",
      "   macro avg       0.81      0.75      0.78     65307\n",
      "weighted avg       0.95      0.95      0.95     65307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([X_valid, X_tfidf_valid]).reshape(-1)\n",
    "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.2470 - accuracy: 0.9266 - val_loss: 0.1776 - val_accuracy: 0.9381\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1521 - accuracy: 0.9445 - val_loss: 0.1347 - val_accuracy: 0.9506\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1303 - accuracy: 0.9518 - val_loss: 0.1263 - val_accuracy: 0.9529\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 97s 1s/step - loss: 0.1241 - accuracy: 0.9534 - val_loss: 0.1233 - val_accuracy: 0.9536\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 97s 1s/step - loss: 0.1204 - accuracy: 0.9543 - val_loss: 0.1214 - val_accuracy: 0.9541\n",
      "Epoch 6/50\n",
      "76/76 [==============================] - 97s 1s/step - loss: 0.1184 - accuracy: 0.9548 - val_loss: 0.1213 - val_accuracy: 0.9543\n",
      "Epoch 7/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1169 - accuracy: 0.9550 - val_loss: 0.1199 - val_accuracy: 0.9545\n",
      "Epoch 8/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1161 - accuracy: 0.9552 - val_loss: 0.1208 - val_accuracy: 0.9538\n",
      "Epoch 9/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1151 - accuracy: 0.9555 - val_loss: 0.1193 - val_accuracy: 0.9545\n",
      "Epoch 10/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1146 - accuracy: 0.9556 - val_loss: 0.1190 - val_accuracy: 0.9546\n",
      "Epoch 11/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1139 - accuracy: 0.9557 - val_loss: 0.1187 - val_accuracy: 0.9550\n",
      "Epoch 12/50\n",
      "76/76 [==============================] - 99s 1s/step - loss: 0.1135 - accuracy: 0.9559 - val_loss: 0.1185 - val_accuracy: 0.9548\n",
      "Epoch 13/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1130 - accuracy: 0.9561 - val_loss: 0.1185 - val_accuracy: 0.9549\n",
      "Epoch 14/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1127 - accuracy: 0.9562 - val_loss: 0.1186 - val_accuracy: 0.9550\n",
      "Epoch 15/50\n",
      "76/76 [==============================] - 98s 1s/step - loss: 0.1125 - accuracy: 0.9563 - val_loss: 0.1188 - val_accuracy: 0.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32782f80f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(embedding_dim=100, pooling_fn=average, hidden=64, lr=0.01)\n",
    "\n",
    "model.fit([X_train, X_tfidf_train], y_train,\n",
    "          validation_data=([X_valid, X_tfidf_valid], y_valid),\n",
    "          batch_size=16384,\n",
    "          callbacks=callbacks,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     61266\n",
      "           1       0.68      0.52      0.59      4041\n",
      "\n",
      "    accuracy                           0.96     65307\n",
      "   macro avg       0.82      0.75      0.78     65307\n",
      "weighted avg       0.95      0.96      0.95     65307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([X_valid, X_tfidf_valid]).reshape(-1)\n",
    "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "76/76 [==============================] - 91s 1s/step - loss: 0.3254 - accuracy: 0.9303 - val_loss: 0.1289 - val_accuracy: 0.9522\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 91s 1s/step - loss: 0.1239 - accuracy: 0.9535 - val_loss: 0.1218 - val_accuracy: 0.9542\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 91s 1s/step - loss: 0.1184 - accuracy: 0.9553 - val_loss: 0.1201 - val_accuracy: 0.9552\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 91s 1s/step - loss: 0.1156 - accuracy: 0.9564 - val_loss: 0.1205 - val_accuracy: 0.9541\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 91s 1s/step - loss: 0.1133 - accuracy: 0.9572 - val_loss: 0.1203 - val_accuracy: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f327817df28>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(embedding_dim=100, pooling_fn=add, hidden=64, lr=0.01)\n",
    "\n",
    "model.fit([X_train, X_tfidf_train], y_train,\n",
    "          validation_data=([X_valid, X_tfidf_valid], y_valid),\n",
    "          batch_size=16384,\n",
    "          callbacks=callbacks,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     61266\n",
      "           1       0.68      0.51      0.58      4041\n",
      "\n",
      "    accuracy                           0.95     65307\n",
      "   macro avg       0.82      0.75      0.78     65307\n",
      "weighted avg       0.95      0.95      0.95     65307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([X_valid, X_tfidf_valid]).reshape(-1)\n",
    "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extra: tf-idf averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "76/76 [==============================] - 93s 1s/step - loss: 0.1717 - accuracy: 0.9375 - val_loss: 0.1337 - val_accuracy: 0.9525\n",
      "Epoch 2/50\n",
      "76/76 [==============================] - 95s 1s/step - loss: 0.1233 - accuracy: 0.9543 - val_loss: 0.1252 - val_accuracy: 0.9540\n",
      "Epoch 3/50\n",
      "76/76 [==============================] - 92s 1s/step - loss: 0.1111 - accuracy: 0.9573 - val_loss: 0.1235 - val_accuracy: 0.9550\n",
      "Epoch 4/50\n",
      "76/76 [==============================] - 94s 1s/step - loss: 0.1035 - accuracy: 0.9592 - val_loss: 0.1244 - val_accuracy: 0.9545\n",
      "Epoch 5/50\n",
      "76/76 [==============================] - 96s 1s/step - loss: 0.0977 - accuracy: 0.9609 - val_loss: 0.1265 - val_accuracy: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f321c2ba6d8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(embedding_dim=100, hidden=64, dropout_rate=0.2, lr=0.01)\n",
    "\n",
    "model.fit([X_train, X_tfidf_train], y_train,\n",
    "          validation_data=([X_valid, X_tfidf_valid], y_valid),\n",
    "          batch_size=16384,\n",
    "          callbacks=callbacks,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     61266\n",
      "           1       0.64      0.57      0.60      4041\n",
      "\n",
      "    accuracy                           0.95     65307\n",
      "   macro avg       0.80      0.77      0.79     65307\n",
      "weighted avg       0.95      0.95      0.95     65307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([X_valid, X_tfidf_valid]).reshape(-1)\n",
    "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tf-idf averaging allows us to gain an extra point in the f1-score with macro averaging, which is often the most suitable metric for an unbalanced classification task. However, the gain is not significant enough compared to normal averaging. Moreover, we lose one point in accuracy. Overall, there is no need to do the extra work here since unweighted averaging produces a result that is almost identical to this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
