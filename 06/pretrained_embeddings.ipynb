{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from typing import List, Dict, Callable\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Concatenate, Average\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                             question_text  target  \n",
       "0        How did Quebec nationalists see their province...       0  \n",
       "1        Do you have an adopted dog, how would you enco...       0  \n",
       "2        Why does velocity affect time? Does velocity a...       0  \n",
       "3        How did Otto von Guericke used the Magdeburg h...       0  \n",
       "4        Can I convert montra helicon D to a mountain b...       0  \n",
       "...                                                    ...     ...  \n",
       "1306117  What other technical skills do you need as a c...       0  \n",
       "1306118  Does MS in ECE have good job prospects in USA ...       0  \n",
       "1306119                          Is foam insulation toxic?       0  \n",
       "1306120  How can one start a research project based on ...       0  \n",
       "1306121  Who wins in a battle between a Wolverine and a...       0  \n",
       "\n",
       "[1306122 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('quora.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> List[str]:\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return [token for token in tokens if token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:16<00:00, 80362.87it/s] \n"
     ]
    }
   ],
   "source": [
    "preprocessed = [preprocess(text) for text in tqdm(data.question_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = max(len(tokens) for tokens in preprocessed)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for tokens in preprocessed:\n",
    "    vocab.update(tokens)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_vocab = {word for word, count in vocab.items() if count >= 50}\n",
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {'<PAD>': 0, '<UNK>': 1}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for tokens in preprocessed:\n",
    "    ids = [word2id.get(token, 1) for token in tokens]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 132)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(X, maxlen=MAX_LEN)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.target.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 958.4/958.4MB downloaded\n",
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14258/14258 [00:00<00:00, 38539.19it/s]\n"
     ]
    }
   ],
   "source": [
    "ft_matrix = np.zeros((len(word2id), 300))\n",
    "ft = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "glove_matrix = np.zeros((len(word2id), 300))\n",
    "glove = api.load('glove-wiki-gigaword-300')\n",
    "\n",
    "ft_unk_indices = []\n",
    "glove_unk_indices = []\n",
    "\n",
    "for word, idx in tqdm(word2id.items()):\n",
    "    if word == '<PAD>':\n",
    "        continue\n",
    "    \n",
    "    if word == '<UNK>':\n",
    "        ft_unk_indices.append(idx)\n",
    "        glove_unk_indices.append(idx)\n",
    "        \n",
    "    try:\n",
    "        ft_matrix[idx] = ft[word]\n",
    "    except KeyError:\n",
    "        ft_unk_indices.append(idx)\n",
    "    \n",
    "    try:\n",
    "        glove_matrix[idx] = glove[word]\n",
    "    except KeyError:\n",
    "        glove_unk_indices.append(idx)\n",
    "\n",
    "ft_mean_vector = np.mean(np.vstack([vector for i, vector in enumerate(ft_matrix) if i not in ft_unk_indices]), axis=0)\n",
    "for idx in ft_unk_indices:\n",
    "    ft_matrix[idx] = ft_mean_vector\n",
    "        \n",
    "glove_mean_vector = np.mean(np.vstack([vector for i, vector in enumerate(glove_matrix) if i not in glove_unk_indices]), axis=0)\n",
    "for idx in glove_unk_indices:\n",
    "    glove_matrix[idx] = glove_mean_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embedding experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst):\n",
    "    return Average()(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(lst):\n",
    "    return Concatenate()(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_dim: int = 100, pooling_fn: Callable = average,\n",
    "                hidden: int = 64, dropout_rate: float = 0.1, l2_rate: float = 1e-4,\n",
    "                output_dim: int = 1, lr: float = 1e-3):\n",
    "    inputs = Input(shape=(MAX_LEN,))\n",
    "    \n",
    "    embeddings1 = Embedding(input_dim=len(word2id), output_dim=embedding_dim, weights=[ft_matrix], trainable=False)(inputs)\n",
    "    embeddings2 = Embedding(input_dim=len(word2id), output_dim=embedding_dim, weights=[glove_matrix], trainable=False)(inputs)\n",
    "    \n",
    "    embeddings = pooling_fn([embeddings1, embeddings2])\n",
    "    pool = tf.math.reduce_mean(embeddings, axis=1)\n",
    "    pool = Dropout(dropout_rate)(pool)\n",
    "    \n",
    "    dense = Dense(hidden, activation='relu', kernel_regularizer=regularizers.l2(l2_rate))(pool)\n",
    "    dense = Dropout(dropout_rate)(dense)\n",
    "    \n",
    "    activation = 'sigmoid' if output_dim == 1 else 'softmax'\n",
    "    outputs = Dense(output_dim, activation=activation, kernel_regularizer=regularizers.l2(l2_rate))(dense)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    loss = 'binary_crossentropy' if output_dim == 1 else 'categorical_crossentropy'\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(patience=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.2308 - accuracy: 0.9352 - val_loss: 0.1772 - val_accuracy: 0.9431\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.1750 - accuracy: 0.9424 - val_loss: 0.1674 - val_accuracy: 0.9446\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.1694 - accuracy: 0.9432 - val_loss: 0.1635 - val_accuracy: 0.9452\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.1673 - accuracy: 0.9436 - val_loss: 0.1629 - val_accuracy: 0.9463\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 202s 1s/step - loss: 0.1662 - accuracy: 0.9444 - val_loss: 0.1618 - val_accuracy: 0.9454\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 204s 1s/step - loss: 0.1659 - accuracy: 0.9448 - val_loss: 0.1612 - val_accuracy: 0.9458\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 205s 1s/step - loss: 0.1653 - accuracy: 0.9450 - val_loss: 0.1615 - val_accuracy: 0.9467\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 203s 1s/step - loss: 0.1651 - accuracy: 0.9453 - val_loss: 0.1617 - val_accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a885fc4e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(embedding_dim=300, pooling_fn=concatenate, hidden=256, lr=0.005, dropout_rate=0.2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=8192,\n",
    "          callbacks=callbacks,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     61266\n",
      "           1       0.71      0.20      0.31      4041\n",
      "\n",
      "    accuracy                           0.95     65307\n",
      "   macro avg       0.83      0.60      0.64     65307\n",
      "weighted avg       0.93      0.95      0.93     65307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_valid).reshape(-1)\n",
    "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - 149s 982ms/step - loss: 0.2482 - accuracy: 0.9361 - val_loss: 0.2006 - val_accuracy: 0.9381\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 150s 988ms/step - loss: 0.1953 - accuracy: 0.9381 - val_loss: 0.1876 - val_accuracy: 0.9381\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 149s 977ms/step - loss: 0.1865 - accuracy: 0.9381 - val_loss: 0.1805 - val_accuracy: 0.9381\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 149s 978ms/step - loss: 0.1827 - accuracy: 0.9385 - val_loss: 0.1776 - val_accuracy: 0.9425\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.1809 - accuracy: 0.9422 - val_loss: 0.1764 - val_accuracy: 0.9437\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 151s 996ms/step - loss: 0.1798 - accuracy: 0.9430 - val_loss: 0.1756 - val_accuracy: 0.9438\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 151s 992ms/step - loss: 0.1795 - accuracy: 0.9434 - val_loss: 0.1749 - val_accuracy: 0.9444\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 149s 978ms/step - loss: 0.1794 - accuracy: 0.9437 - val_loss: 0.1752 - val_accuracy: 0.9438\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 155s 1s/step - loss: 0.1792 - accuracy: 0.9438 - val_loss: 0.1752 - val_accuracy: 0.9439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a80581320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(embedding_dim=300, hidden=256, lr=0.005, dropout_rate=0.2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=8192,\n",
    "          callbacks=callbacks,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     61266\n",
      "           1       0.71      0.16      0.26      4041\n",
      "\n",
      "    accuracy                           0.94     65307\n",
      "   macro avg       0.83      0.58      0.61     65307\n",
      "weighted avg       0.93      0.94      0.93     65307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_valid).reshape(-1)\n",
    "print(classification_report(y_valid, (preds > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concatenation of embeddings works better which is in agreement with our expectations: after all, different word vectors will have different dimensions of meaning, therefore, averaging them might not be a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
